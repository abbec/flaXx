\documentclass[a4paper]{report}

\usepackage{graphicx}
\usepackage{amsmath, amsthm}

% To get slightly smaller margins
\usepackage{fullpage}

% To get paragraphs right
\usepackage[parfill]{parskip}

% Correct input encoding
\usepackage[utf8x]{inputenc}

% For URL:s
\usepackage{url}

% For subfigures
\usepackage{subfig}

\begin{document}

\title{FlaXx: A Monte-Carlo (Stochastic) Ray Tracer}
\author{Nathalie Ek \and Albert Cervin}

\maketitle

\begin{abstract}
Abstract goes here.
\end{abstract}

\tableofcontents

\listoffigures

\chapter{Introduction}

\section{Global Illumination}

The problem of global illumination has existed just as long as images
have been produced with computers. The problem consists of solving the
rendering equation. The hemispherical formulation of the rendering equation is

\begin{equation}
  L(x \to \Theta) = L_e(x \to \Theta) + \int_{\Omega_x}f_r(x,\Psi \to \Theta)L(x \gets \Psi)\cos{N_x,\Psi}d\omega_\Psi
  \label{eq:renderingeq}
\end{equation}

where \(L(x \to \Theta)\) is the radiance going from the point \(x\)
in direction \(\Theta\), \(L_e(x \to \Theta) \) is the self-emitted
radiance from the point \(x\) in direction \(\Theta\), \(f_r(x,\Psi
\to \Theta)\) is the Bidirectional Reflectance Distribution Function
(BRDF) which tells how much of the incoming light from direction
\(\Psi\) to the point \(x\) is leaving in direction \(\Theta\). The
BRDF is material-dependent and will look different for different materials.

\subsection{Whitted Ray tracing}

The first usable solution to this problem was proposed by Turner
Whitted \cite{whitted} in 1980. Whitted proposed a ray-tracing scheme
where only perfect specular reflection and refraction is
considered. This means that in each intersection point, one reflected
and one refracted ray are spawned. This results in a recursive
solution to the rendering equation (\ref{eq:renderingeq}). To take
diffuse interactions into consideration, a local
lighting model is used where rays are cast towards the light source
from the ray intersection point with an object. This solves the
problem with shadows and diffuse objects. However, this method stops
the recursion as soon as a diffuse surface is hit and thus does not
take diffuse interreflections into consideration.

\subsection{Radiosity}

Another method that takes diffuse interreflections into consideration
is the radiosity method, proposed by Goral et al. \cite{goral}. The
radiosity method divides the scene into patches and a set of equations
is set up, based on the conservation of light energy. The light transport
between these patches are then calculated. Every patch in the
environment gets reflected light from all other patches in the
scene. A patch can also emit light if it is a light source. This is
represented by the radiosity formula.

\begin{equation}
  B_i = E_i + R_i\sum^n_{j=1}B_jF_{ij}
  \label{eq:radiosity}
\end{equation}

In this equation (\ref{eq:radiosity}), \(B_i\) is the radiosity for
patch \(i\), \(E_i\) is the energy emitted from the same patch,
\(R_i\) is the reflectivity of the patch and the sum is a sum over all
the other patches radiosity \(B_j\), weighted by the form factor
between patch \(i\) and \(j\), \(F_{ij}\). Equation \ref{eq:radiosity}
exists for every patch present in the scene and therefore the solution
to this equation becomes the solution of a set of \(n\) simultaneous equations.

The form factors, as stated above, take the geometric relation between
two patches into consideration. It can be noted that \(F_{ii} = 0 \)
for a plane and convex surface. In words, the calculation of the form
factors can be expressed as

\begin{equation}
  F_{ij} = \frac{\text{Radiative energy leaving surface } A_i \text{ that
    strikes } A_j \text{ directly}}{\text{Radiative energy leaving
    surface } A_i \text{in all directions in the hemispherical space
    surrounding } A_i}
\end{equation}.

\subsection{Monte Carlo ray tracing}

This method is also called stochastic ray tracing. Essentially it is
an application of Monte Carlo integration methods in 3D computer
graphics. Instead of just considering one reflected and one refracted
ray in intersections as is the case with Whitted ray tracing, many
rays are considered (sampled). The same method for shadows and direct
illumination is used where shadow rays are shot towards the
lightsource to determine visibility (shadows) and illumination. The
indirect illumination scheme is quite different from the Whitted
scheme, though. When a ray intersects a surface in the scene, the
material properties are considered and according to that multiple rays
are cast. The most important directions for the final image have a
higher probability of being sampled. This is in Monte Carlo methods
known as importance sampling, which simply means that more important
directions are sampled more frequently in a ray tracer. This yields a
lower variance meaning that the method will converge to an accurate
solution of the equation faster.

Monte Carlo integration techniques rely on the relation saying that the expectation value
of an estimator is exactly the value of the integral.

If we have an integral \(I\), the estimator \(\langle I \rangle\) is

\begin{equation}
  \langle I \rangle = \frac{1}{N}\sum^N_{i=1}\frac{f(x_i)}{p(x_i)}.
  \label{eq:estimator}
\end{equation}

It can be shown that 

\begin{equation}
  E[\langle I \rangle] = I
\end{equation}

where \(I\) is the integral to be estimated.

This shows that the more samples used in the estimator, the more
accurate is the estimation of I.

Since ray tracing is a recursive procedure, the tracing has to be
stopped at some point. If this is done by limiting the recursive depth
to a constant number, the image will be biased and there will be
visible effects in the final image. Instead a stopping condition
called Russian roulette is used. This means that in each ray
intersection there is a certain probability for the evaluation to
stop. This way, the recursive depth can depend on for instance the
local hemispherical reflectance of the surface hit by a ray. Russian
roulette will produce an unbiased image.

To get rid of aliasing effect and to further lower the variance, many
rays are shot into the scene per pixel. In this way the need for
spawning many rays at each intersection point diminishes and therefore
few rays are spawned at the intersection point and instead more
viewing rays are used. With stochastic (Monte Carlo) raytracing it is
hard to model caustic effects though but this can be done with another
global illumination method called photon mapping.

\subsection{Photon mapping}

Photon mapping was proposed as a global illumination algorithm by
Henrik Wann Jensen \cite{jensen} in 1996. Rays from the light source
and from the camera are traced independently and then combined in a
second step to produce a radiance estimate. This makes it possible to
simulate reflection and refraction in a better way, taking caustics
into consideration. Photon mapping is a ``biased'' algorithm meaning
that more passes of the algorithm will not give a more accurate
solution. Using more photons will however give a more correct solution.

The first pass in the algorithm is creating the photon maps. Photons
are sent out from the light sources and when the photon intersects an
object in the scene, the intersection point and the incoming direction
is stored in a cache called the photon map. After this, Russian
roulette (see above) is used to evaluate the next action for the
photon: absorption, transmission or reflection. The photon map is
typically stored in a kd-tree for fast nearest neighbor searching. The
map is then stored for later use.

The second pass is a ray tracing pass where a ray is shot from the
camera and then an intersection point is found. Direct illumination in
this point is evaluated with the same scheme as in the above ray
tracing algorithms. For indirect illumination however, the photon map
is used. Specular reflection is handled well by standard ray tracers
and is therefore done by the ray tracing algorithm. For soft indirect
illumination, the global photon map is used. For caustics, the other
photon map, called the caustic photon map is used.

In order to calculate surface radiance at an intersection point, one
of the cached photon maps is used. The steps are:

\begin{enumerate}
\item{Gather the N nearest photons using the nearest neighbor search function on the photon map.}
\item{Let S be the sphere that contains these N photons.}
\item {For each photon, divide the amount of flux (real photons) that
    the photon represents by the area of S and multiply by the BRDF applied to that photon.}
\item{The sum of those results for each photon represents total
    surface radiance returned by the surface intersection in the
    direction of the ray that struck it.}
\end{enumerate}

\section{Introduction}
This first section is an introduction to the global illumination problem and different
solutions proposed. In the next chapter Monte Carlo raytracing will be
discussed more in detail, and details of our implementation will be
presented. In chapter \ref{ch:results} results from the implementation
is presented and discussed. Discussion and outlook is presented in chapter \ref{ch:discussion}. 

\chapter{Background}

A Monte Carlo ray tracer has been implemented in C++ and here the
implementation details will be presented. The algorithm will be
described in the order it runs. That is, first the camera and the view
plane is described, then ray-surface intersections and after that the
calculation of direct and indirect illumination in a given
intersection point.

\section{Setting up the render}

The first thing is to create a render object which will hold and
gather all information regarding the render. This is created with
options from the command line provided by a user. The number of
viewing rays, number of shadow rays, number of indirect rays, image
dimensions etc. can be specified. The render object also creates an
image plane object which is responsible for providing world
coordinates for a pixel and for dividing the image into a number of
tiles to be rendered.

The pixels in the image are divided into ten tiles in \(x\)-direction and
a corresponding number to have the tiles quadratic, in
\(y\)-direction. The tiles closest to the middle of the image are
selected for rendering first, since the middle of the image are in
most cases the most interesting. This way there is no need to sit and
wait for the render to reach the middle of the image. The middle means
in this case the center of the image in \(x\)-direction.

\section{Camera and view plane}
\label{sec:cam}

The camera is placed by default in the origin \((0, 0, 0)\) and the
viewing direction is by default in positive \(z\)-direction. That
means that positive \(Z\) is into the screen. The view plane is
defined to have a width that can be varied by varying the field of
view for the camera. The camera also has a depth of field setting that
can be varied to achieve different depth field effects \footnote{Not
  currently implemented}.

Multiple rays can be shot through each pixel and stratified sampling
is used to avoid clamping of samples in the pixel. The pixel is
subdivided into the nearest even square number of the number of
viewing rays requested. For example, if 1000 viewing rays are
requested, the pixel is subdivided into \(\lceil \sqrt{1000}
\rceil^2 = 1024 \) subpixels. A ray is then shot through a jittered
center point of the sub-pixel. This gives a result as in figure. %REF


\section{Intersection tests}

The scenes in this implementation consists of spheres, planes and
polygonal objects \footnote{Planned}. Intersections between rays and
these object has to be carried out.

\subsection{Ray-triangle intersection}

To check if a ray intersects a triangle has to be done for both planes
(which consists of two triangles) and for polygonal objects. These
tests are done with barycentric coordinates \cite{pointTest:10}. First, a point on the ray
is projected onto the same plane as the triangle lies in:

\begin{equation}
  P = R_o - R_d\frac{(R_o-v_1) \cdot N}{R_d \cdot N}
  \label{eq:planeproj}
\end{equation}

where \(P\) is the resulting point, \(R_o\) is the origin of the ray
\(R\), \(R_d\) is the direction of the same ray, \(v_1\) is the first
vertex on the triangle and \(N\) is the normal of the triangle.

After this the sides of the triangle is parametrized into \(u\) and
\(v\). To do this, intermediate vectors \(i_1\), \(i_2\) and \(i_3\)
are created as follows:

\begin{align}
  i_1 &= v_2 - v_1 \nonumber \\
  i_2 &= v_3 - v_1 \nonumber \\
  i_3 &= P - v_1
  \label{eq:intermediate}
\end{align}

where \(v_i\) is vertex point \(i\) on the triangle and \(P\) is the point calculated
in equation \ref{eq:planeproj}. Now \(u\) and \(v\) can be calculated:

\begin{align}
  u &= \frac{(i_2 \cdot i_2)(i_1 \cdot i_3) - (i_1 \cdot i_2)(i_2
    \cdot i_3)}{(i_1 \cdot i_1)(i_2 \cdot i_2) - (i_1 \cdot i_2)(i_1
    \cdot i_2)} \nonumber \\
  v &= \frac{(i_1 \cdot i_1)(i_2 \cdot i_3) - (i_1 \cdot i_2)(i_1
    \cdot i_3)}{(i_1 \cdot i_1)(i_2 \cdot i_2) - (i_1 \cdot i_2)(i_1
    \cdot i_2)}.
  \label{eq:uandv}
\end{align}

After calculation \(u\) and \(v\) the only thing left is to check that
\(u,v \geq 0\) and that \(u+v \leq 1\). If that is the case, the ray
is intersecting the sphere. A situation where this holds is
illustrated in figure %\ref{fig:pointintriangle}.

For planes, this test has to be done for both triangles in the plane
since the planes are essentially polygonal objects with two polygons.

\subsection{Ray-sphere intersection}

In this implementation spheres are implicit object (as opposed to
polygonal ones) and to calculate intersection with such a sphere the
distance \(D\) from the ray start \(R_o\) and the sphere center \(S_c\) is
calculated. A parameter \(b\) is also calculated 

\begin{equation}
 b = D R_d
 \label{eq:b}
\end{equation}

where \(R_d\) is the ray direction.

After this it can be checked that \(b \geq 0\) and that \(D \leq
radius^2\). If that is not true, the ray does not intersect the
sphere.

If the above is true though, further calculations has to be carried
out. An additional parameter \(c\) is calculated

\begin{equation}
  c = D - b²
\end{equation}

where \(D\) is the distance calculated above and \(b\) is the
parameter calculated in equation \ref{eq:b}.

Another check can now be performed to see that \(c \leq radius^2\). If
that is not true, there is no intersection.

Otherwise the intersection point is

\begin{equation}
  d = \sqrt{radius^2 - c}
  \label{eq:d}
\end{equation}

\begin{equation}
  P = \left \{ 
  \begin{array}{l l}
    R_o + R_d *(b-d) & \quad D \geq radius^2 \\
    R_o + R_d *(b+d) & \quad \text{otherwise} \\
  \end{array} \right.
\end{equation}

where \(P\) is the resulting intersection point, \(R_o\) and \(R_d\)
is the origin and direction of ray \(R\), respectively, \(b\) is the
parameter calculated in equation \ref{eq:b} and \(d\) is the parameter
calculated in equation \ref{eq:d}.

In the current implementation light sources are deliberately excluded
from the intersection tests. This was done because the ability to have
objects represent light sources was wanted. Future improvements are
needed to make this work in a good way though. This will be discussed more in
chapter \ref{ch:discussion}.

\section{BRDF and materials}

Materials are implemented as separate object and every material
inheriting from the base material has to have a BRDF function telling
what color the object shall have in a specific point given incoming
and outgoing direction. Currently a Lambert and a modified Blinn-Phong
BRDF are implemented. Some experimenting with a Cook-Torrance shader
was also done but was put on the to-do-list.

Each material also has a color and if refractive properties are set
for the material, the refractive index has to be set.

The diffuse \(k_d\) and specular \(k_s\) components of the material
has in this implementation to always sum up to at most 1, since a
material with \(k_d = 0\) and \(k_s = 1\) is considered to be a
perfectly specular material. 

\section{Direct illumination calculation}

After an intersection point has been found the direct illumination
contribution to that point is calculated. This is done by casting
multiple shadow rays towards the light source. If more than one light
source exist in the scene, one of the light sources are picked
uniformly with a random number. 

After the light source has been picked, a point on its surface is
sampled (in the case it is an area light source). This is also done uniformly.

The Monte Carlo estimator for direct illumination then becomes

\begin{equation}
  \langle L_{direct}(x \to \Theta) \rangle = \frac{N_L}{N}\sum^N_{i=1}
  A_{L_k}L_e(y_i \to \vec{y_ix})f_r(x,\Theta \leftrightarrow
  \vec{xy_i})G(x,y_i)V(x,y_i)
  \label{eq:direst}
\end{equation}

where \(N_L\) is the number of light sources, \(A_{L_k}\) is the area
of the light source, \(L_e\) is the emittance of the light source,
\(f_r\) is the BRDF of the surface, \(G\) is the geometry term and \(V\) is the
visibility term.

\(V\) and \(G\) are then left to be calculated. \(V\) is a boolean
term telling if the light source point \(y_i\) is visible from the
object point \(x\). If the light source point is visible \(V = 1\)
otherwise it is \(0\).

The geometry term \(G\) takes the geometric relation between point
\(x\) on the object and point \(y_i\) on the light source. It is
expressed as

\begin{equation}
  G(x,y_i) = \frac{(N_x \cdot \Psi)({N_Y}_i \cdot -\Psi)}{{r^2_{xy}}_i}
  \label{eq:geometry}
\end{equation}

where \(N_x\) is the normal at point \(x\), \(\Psi\) is the vector
between point \(x\) and \(y_i\), \({N_y}_i\) is the normal at point
\({N_y}_i\) and \({r^2_{xy}}_i\) is the square of the distance between
point \(x\) and \(y_i\).

After calculation of visibility and geometry everything needed for
calculating the direct illumination at point \(x\) is known. The
direct illumination is then added to the total estimated radiance.

The algorithm is then repeated for the number of shadow rays decided
by the user of the software.

\section{Indirect illumination}

The next step in estimating the radiance is to evaluate the indirect
illumination at the intersection point \(x\). This is done by
evaluating the hemispherical integral in the rendering equation
(\ref{eq:renderingeq}). A Monte Carlo scheme is applied to this
integral since it is clear that no exact solution to this integral can
be achieved. 

A recursive nature can be seen in the equation (\ref{eq:renderingeq})
and therefore a recursive algorithm suits well to solve the
equation. Russian roulette is used to determine the event at each
intersection point. The specular (\(k_s\)) and diffuse (\(k_d\)) components are summed up
to represent the local hemispherical reflectance. A uniform random
number is then generated and if the number is smaller than (\(k_d\)), a
diffuse reflection takes place. If the random number is larger than
 (\(k_d\)) but smaller than (\(k_s+k_d\)) a specular reflection or
 refraction takes place, depending on the reflective and refractive
 parts of the material. If the generated random number does not
 fulfill any of these two criteria, the ray is considered to be
 absorbed and the recursion is stopped. This imposes the condition
 that \(k_s+k_d \leq 1\). 

Directions on the hemisphere are sampled. In this
implementation importance sampling is done according to the following sections.

\subsection{Diffuse reflections}
For diffuse surfaces a cosine lobe around the normal in the point
\(x\) is used to spawn rays. The PDF for such a distribution of rays
is 

\begin{equation}
  p(\Theta) = \frac{n+1}{2\pi}\cos^n{\theta}
  \label{eq:cosnormal}
\end{equation}

where \(\theta\) is the incoming angle and \(n\) is a number between 0
and 1 to control the width of the cosine lobe. \(n=0\) gives a uniform
distribution around the whole hemisphere.

To sample directions according to equation \ref{eq:cosnormal} these
relations are used

\begin{align}
  \varphi &= 2 \pi r_1 \nonumber \\
  \theta &= \cos^{-1}(r_2^{\frac{1}{n+1}})
\end{align}

where \(r_1\) and \(r_2\) are two uniform random numbers and
\(varphi\) and \(\theta\) is the sampled hemispherical coordinates. The sampled
directions are then rotated to match the normal direction at \(x\).

\subsection{Specular reflections}

In the implementation, a specular component of 1 is considered to be a
perfect specular object and therefore a linear interpolation between a
sampled direction and the perfect reflection direction is made.

The interpolation can be described as

\begin{equation}
  D = k_sD_p + (1-k_s)D_s
\end{equation}

where \(D\) is the final direction, \(k_s\) is the specular
component of the material, \(D_p\) is the perfect specular reflection
direction and \(D_s\) is the sampled direction according to the
sampling scheme in equation \ref{eq:cossolid}.

The sampled direction is obtained by a cosine lobe around the perfect
reflection direction. The PDF for this sampling is

\begin{equation}
  p(\Theta) = \frac{\cos{\theta}}{\pi}
\end{equation}

where \(\theta\) is the incoming angle. To sample according to this
PDF equation \ref{eq:cossolid} can be used.

\begin{align}
  \varphi &= 2 \pi r_1 \nonumber \\
  \theta &= \cos^{-1}(\sqrt{r_2})
  \label{eq:cossolid}
\end{align}

where \(r_1\) and \(r_2\) are two uniform random numbers and
\(varphi\) and \(\theta\) is the sampled hemispherical coordinates. The sampled
directions are then rotated to match the perfect reflection direction
at \(x\).

\subsection{Specular refractions}

Russian roulette is used to determine the type of event at point \(x\)
so if the object is specular, the type of action (reflection or
refraction) is determined by comparing a uniform random number with
the transmission coefficient of the material. If the random number is
smaller, a refracted ray is constructed in exactly the same way as is
the case with specular reflections described in the section above.

However, the refracted direction is calculated according to Snells law
and before determining the event at point \(x\), a check to see if the
ray comes from inside or outside the object is made. If the ray comes
from the inside, a refracted ray out from the object is always
spawned.

When handling refractions, nothing can be assumed about the
transparent side of the BRDF so in this implementation a simple
constant is used as BSSDF.

\subsection{Recursive evaluation}

The radiance at point \(x\) is then calculated by shooting a ray in
the sampled direction and apply the same scheme there. The Russian
roulette scheme described above is used to determine the action in
each point. The number of sampled rays launched at each point is
pre-determined and this creates a recursive tree for indirect illumination.

\section{Setting the final color}

The indirect and direct illumination are summed together and is
then normalized linearly. SDL (\url{libsdl.org}) is used for
displaying a window and for saving the image to a png-file. After
normalization, values are set for the two SDL-surfaces. Then the
algorithm proceeds with the next viewing ray.

\chapter{Results and benchmarks}
\label{ch:results}

\section{Aliasing}

To get rid of aliasing effects in the image, jittered sampling is used
as described in section \ref{sec:cam}.

\begin{figure}
  \centering
  \subfloat[Without
  anti-aliasing]{\label{fig:alias}\includegraphics[width=8cm]{figures/500vr}}                
  \subfloat[With anti-aliasing]{\label{fig:aalias}\includegraphics[width=8cm]{figures/aa}}
  \caption{Anti aliasing vs Aliasing}
  \label{fig:aliasingcomp}
\end{figure}

The left image (\ref{fig:alias}) shows an image
without jittered sampling just shooting multiple rays through the
center of the pixel while the right image (\ref{fig:aalias}) shows an image where
jittered sampling is used. In figure (\ref{fig:alias}) the aliasing
effects can clearly be seen in the jagged edges in object boundaries
but can also clearly be seen where the walls meet the floor. This is
natural since the rays shot through the pixel always intersects with
the scene in the same way. 

When jittered sampling is used, the aliasing effects is
diminished. Both images in figure \ref{fig:aliasingcomp} have been
produced with 500 viewing rays. The problem with jittered sampling
though is that it uses \(N^2\) samples in the jitter. A possible
improvement to this could be to use N-rooks that only needs to use
\(N\) samples to achieve the same result. However this would result in
fewer indirect rays at each point and thus a less accurate solution to
the rendering equation.

\section{Obtaining an accurate solution}

\section{Varying lights}

\section{Rendering speed}

\chapter{Discussion}
\label{ch:discussion}


% References
\bibliographystyle{ieeetr}
\bibliography{refs}

\end{document}

Maybe we should cite total compendium?